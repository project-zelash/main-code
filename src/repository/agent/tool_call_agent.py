from src.repository.agent.base_agent import BaseAgent
from src.repository.data_flow.memory_system import MemorySystem
from src.repository.llm.gemini_llm import extract_tool_code_block
import json
import logging
import re
from typing import List, Dict, Any, Optional

# Set up logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class ToolCallAgent(BaseAgent):
    """
    Agent that can use tools through the LLM tool calling API.
    """
    
    def __init__(self, llm, tools, system_prompt, name, verbose=False, max_iterations=20):
        """
        Constructor that sets up tool-enabled agent.
        
        Args:
            llm: Language model instance used by the agent.
            tools: List of BaseTool instances available to the agent.
            system_prompt: Instructions that guide agent behavior.
            name: String identifier for the agent.
            verbose: Boolean flag for detailed logging.
            max_iterations: Maximum tool calling iterations before stopping.
        """
        super().__init__(llm, system_prompt, name, verbose)
        self.tools = tools or []
        self.max_iterations = max_iterations
        self.memory = MemorySystem()
        self.current_iteration = 0
        
        # Create tool mapping for easy lookup
        self.tool_map = {tool.name: tool for tool in self.tools}
        
        if self.verbose:
            logger.info(f"üöÄ Initialized {self.name} with {len(self.tools)} tools")
    
    def _is_valid_codegen_response(self, content):
        """
        Validate that the LLM response is a JSON array of dicts with 'path' and 'content'.
        """
        try:
            # Remove markdown/code block wrappers if present
            # Try multiple patterns to extract JSON content
            json_content = content.strip()
            
            # Pattern 1: ```json ... ```
            match = re.search(r'```json\s*(.*?)```', content, re.DOTALL)
            if match:
                json_content = match.group(1).strip()
            else:
                # Pattern 2: ``` ... ``` (without json specifier)
                match = re.search(r'```\s*(.*?)```', content, re.DOTALL)
                if match:
                    json_content = match.group(1).strip()
            
            # Parse and validate JSON structure
            data = json.loads(json_content)
            if isinstance(data, list) and all(isinstance(x, dict) and 'path' in x and 'content' in x for x in data):
                return True
        except Exception as e:
            logger.debug(f"JSON validation failed: {e}")
            logger.debug(f"Content being validated: {content[:200]}...")
        return False

    def run(self, user_query):
        """
        Executes user queries, potentially using tools.
        
        Args:
            user_query: The query to be processed by the agent.
            
        Returns:
            Response generated by the agent after potentially using tools.
        """
        max_retries = 2
        fallback_prompt = "Your last response was not valid JSON. Return ONLY a JSON array of objects with 'path' and 'content' keys. No explanations, no markdown, just the array."
        try:
            # Initialize the conversation with system prompt and user query
            self.memory.clear()
            self.memory.add_user_message(user_query)
            if self.verbose:
                logger.info(f"üéØ {self.name} received query: {user_query}")
            self.current_iteration = 0
            final_response = ""
            retries = 0
            last_prompt = None
            while self.current_iteration < self.max_iterations:
                self.current_iteration += 1
                if self.verbose:
                    logger.info(f"üîÑ Iteration {self.current_iteration}/{self.max_iterations}")
                messages = self._prepare_messages()
                tools_for_llm = self._prepare_tools() if self.tools else None
                logger.info(f"[LLM CALL] Agent: {self.name}, Iteration: {self.current_iteration}, Prompt: {messages}, Tools: {tools_for_llm}")
                try:
                    response = self.llm.chat(messages, tools=tools_for_llm)
                    logger.info(f"[LLM RESPONSE] Agent: {self.name}, Iteration: {self.current_iteration}, Response: {response}")
                    content = response.get('content', '')
                    # Output validation for codegen tasks
                    if not self._is_valid_codegen_response(content):
                        if retries < max_retries:
                            logger.warning(f"[LLM RETRY] Invalid output, retrying with fallback prompt (attempt {retries+1})")
                            # Add fallback prompt as user message
                            self.memory.add_user_message(fallback_prompt)
                            retries += 1
                            continue
                        else:
                            logger.error(f"[LLM MANUAL INTERVENTION REQUIRED] Agent: {self.name}, Iteration: {self.current_iteration}, Output: {content}")
                            final_response = {
                                "error_type": "ManualInterventionRequired",
                                "error_message": "LLM failed to return valid codegen output after retries.",
                                "llm_output": content,
                                "prompt": messages
                            }
                            break
                    # Extract tool code block if present
                    tool_code = extract_tool_code_block(content)
                    if tool_code:
                        response['tool_code'] = tool_code
                        # Fallback: If it's a bash code block, extract the command and run it
                        bash_command = self._extract_bash_command_from_code_block(tool_code)
                        if bash_command:
                            if self.verbose:
                                logger.info(f"üîß Fallback: Executing bash command from code block: {bash_command}")
                            result = self.tool_map['bash'].run(command=bash_command)
                            self.memory.add_tool_call('bash', {'command': bash_command}, result)
                            final_response = str(result)
                            break
                    
                    # Check if LLM wants to call tools
                    tool_calls = response.get('tool_calls', [])
                    self.memory.add_assistant_message(content)
                    if tool_calls:
                        if self.verbose:
                            logger.info(f"üõ†Ô∏è {self.name} wants to use {len(tool_calls)} tools")
                        # Execute tool calls
                        tool_results = self._process_tool_calls(tool_calls)
                        # Add tool results to memory
                        for i, (tool_call, result) in enumerate(zip(tool_calls, tool_results)):
                            tool_name = tool_call.get('name', f'tool_{i}')
                            tool_args = tool_call.get('arguments', {})
                            self.memory.add_tool_call(tool_name, tool_args, result)
                        # Continue the loop to let LLM process tool results
                        continue
                    else:
                        # No tool calls, we have a final response
                        final_response = content
                        break
                        
                except Exception as e:
                    # Log the raw LLM response if available, even on failure
                    logger.error(f"[LLM FAILURE] Agent: {self.name}, Iteration: {self.current_iteration}, Exception: {str(e)}")
                    if 'response' in locals():
                        logger.error(f"[LLM RAW RESPONSE ON FAILURE] Agent: {self.name}, Iteration: {self.current_iteration}, Response: {response}")
                    final_response = f"I encountered an error: {str(e)}"
                    break
            
            # Check if we exceeded max iterations
            if self.current_iteration >= self.max_iterations and not final_response:
                final_response = "I reached the maximum number of iterations without completing the task."
                if self.verbose:
                    logger.warning(f"‚è∞ {self.name} reached max iterations")
            
            if self.verbose:
                logger.info(f"‚úÖ {self.name} completed in {self.current_iteration} iterations")
            
            return final_response
            
        except Exception as e:
            import traceback
            return {
                "error_type": "AgentException",
                "error_message": str(e),
                "traceback": traceback.format_exc(),
                "input": user_query,
                "agent": getattr(self, 'name', str(self.__class__.__name__))
            }
    
    def _prepare_messages(self):
        """
        Prepare messages for LLM including system prompt.
        
        Returns:
            List of messages formatted for LLM.
        """
        messages = []
        
        # Add system prompt
        if self.system_prompt:
            messages.append({"role": "system", "content": self.system_prompt})
        
        # Add conversation history
        memory_messages = self.memory.get_messages(include_tools=True)
        
        for msg in memory_messages:
            if msg.get("role") == "tool":
                # Format tool messages for LLM
                tool_content = f"Tool '{msg.get('tool_name')}' executed with args {msg.get('args')} and returned: {msg.get('result')}"
                messages.append({"role": "user", "content": tool_content})
            else:
                messages.append(msg)
        
        return messages
    
    def _prepare_tools(self):
        """
        Prepare tools in LLM-compatible format.
        
        Returns:
            List of tool definitions for LLM.
        """
        if not self.tools:
            return None
            
        tools_for_llm = []
        for tool in self.tools:
            tool_def = {
                "type": "function",
                "function": {
                    "name": tool.name,
                    "description": tool.description,
                    "parameters": tool.args_schema
                }
            }
            tools_for_llm.append(tool_def)
        
        return tools_for_llm
    
    def _process_tool_calls(self, tool_calls):
        """
        Processes and executes tool calls from the LLM.
        
        Args:
            tool_calls: List of tool calls from the LLM.
            
        Returns:
            Results from executing the tools.
        """
        results = []
        
        for tool_call in tool_calls:
            try:
                # Extract tool information
                tool_name = tool_call.get('name')
                tool_args = tool_call.get('arguments', {})
                
                if self.verbose:
                    logger.info(f"üîß Executing tool: {tool_name} with args: {tool_args}")
                
                # Check if tool exists
                if tool_name not in self.tool_map:
                    error_result = f"Error: Tool '{tool_name}' not found. Available tools: {list(self.tool_map.keys())}"
                    results.append(error_result)
                    continue
                
                # Parse arguments if they're a string
                if isinstance(tool_args, str):
                    try:
                        tool_args = json.loads(tool_args)
                    except json.JSONDecodeError:
                        error_result = f"Error: Invalid JSON arguments for tool '{tool_name}': {tool_args}"
                        results.append(error_result)
                        continue
                
                # Execute the tool
                tool_instance = self.tool_map[tool_name]
                result = tool_instance.run(**tool_args)
                
                if self.verbose:
                    logger.info(f"‚úÖ Tool '{tool_name}' completed. Result: {str(result)[:100]}...")
                
                results.append(result)
                
            except Exception as e:
                error_result = f"Error executing tool '{tool_name}': {str(e)}"
                logger.error(f"üö® {error_result}")
                results.append(error_result)
        
        return results
    
    def _extract_bash_command_from_code_block(self, code_block):
        """
        Extract the first non-comment, non-echo line from a bash code block.
        """
        for line in code_block.splitlines():
            line = line.strip()
            if line and not line.startswith("#") and not line.startswith("echo"):
                return line
        return None